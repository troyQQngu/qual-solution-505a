\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage[]{amsthm} %lets us use \begin{proof}
\usepackage[]{amssymb} %gives us the character \varnothing
\usepackage[a4paper, total={6in, 8in}]{geometry}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}

\title{MATH 505a Fall 2019 Qual Solution Attempts}
\author{Troy Tao}
\date\today

\begin{document}
\maketitle 
Contact \textcolor{blue}{yntao@usc.edu} if you think this document needs revision.


\section*{Problem 1}
Suppose $A,B,C$ are pairwise independent, $A\cap B\cap C = \emptyset$, and $\prob(A)=\prob(B)=\prob(C)=p$.
\subsection*{(a)}
What is the largest possible value of $p$?
\color{blue}
\\\\\textit{Solution. }First, notice that $A\cap B\cap C = \emptyset \implies (A\cap B)\cap (B\cap C) = \emptyset$. Then 
$$p=\prob(B)\geq\prob(A\cap B)+\prob(B\cap C)=\prob(A)\prob(B)+\prob(B)\prob(C)=2p^2$$
We have
$$p\leq \frac{1}{2}$$
Then, we let $\prob(A)=\prob(B)=\frac{1}{2}$. ($\prob(A\cap B) = \frac{1}{4}$ and $\prob(A \cup B) = \prob(A)+\prob(B) - \prob(A\cap B) = \frac{3}{4}$). And let $C = (A\cup B)\backslash (A\cap B)$. Now we want to show that such $A,B,C$ satisfies the assumptions. 
$$\prob(C) = \prob(A\cup B)-\prob(A\cap B)=\frac{1}{2}$$
$$\prob(C\cap A) = \prob(A)-\prob(A\cap B) = \frac{1}{4}$$
$$\prob(C\cap B) = \prob(B)-\prob(A\cap B) = \frac{1}{4}$$
$$A\cap B\cap C =(A\cap B)\cap((A\cup B)\backslash(A\cap B))=\emptyset$$
Therefore $\frac{1}{2}$ is the largest possible value for $p$.
\color{black}
\subsection*{(b)}
Is it possible that $\prob(A\cup B\cup C)=1$? Prove or disprove.
\color{blue}
\\\\\textit{Solution. }Impossible.
\begin{proof}
By inclusion-exclusion theorem,
\begin{equation*}
    \begin{split}
        \prob(A\cup B\cup C) &= \prob(A)+\prob(B)+\prob(C)-(\prob(A\cap B)+\prob(A\cap C)+\prob(B\cap C))+\prob(A\cap B\cap C)\\
        &= 3p-3p^2
    \end{split}
\end{equation*}
which reaches maximum at $p = 0.5$ and $\prob(A\cup B\cup C)=0.75$.
\end{proof}
\color{black}
\section*{Problem 2}
Consider two coins: coin 1 shows heads with probability $p_1$ and coin 2 shows heads with probability $p_2$. Each coin is tossed repeatedly. Let $T_i$ be the time of first heads for coin $i$, and define the event $A=\{T_1<T_2\}$.
\subsection*{(a)}
Find $\prob(A).$ HINT: One possible method is to condition on one of the variables.
\color{blue}
\\\\\textit{Solution. }Notice that $T_i \sim$ Geometric($p_i$).
\begin{equation*}
    \begin{split}
        \prob(A) &=\sum_{t=2}^\infty\prob(T_1\leq t-1)\prob(T_2=t)\\
        &= \sum_{t=2}^\infty(1-(1-p_1)^{t-1})(p_2(1-p_2)^{t-1})\\
        &=p_2\left(\sum_{t=1}^\infty(1-p_2)^{t}-\sum_{t=1}^\infty[(1-p_2)(1-p_1)]^t\right)\\
        &= \frac{p_1(1-p_2)}{1-(1-p_1)(1-p_2)}
    \end{split}
\end{equation*}
\color{black}
\subsection*{(b)}
Find $\prob(T_1=k\vert A)$ for all $k\geq 1$.
\color{blue}
\\\\\textit{Solution. }
\begin{equation*}
    \begin{split}
        \prob(T_1=k\vert A) &= \frac{\prob(T_1=k)\prob(T_2>k)}{\prob(A)}\\
        &= \frac{[1-(1-p_1)(1-p_2)](1-p_1)^{k-1}p_1(1-p_2)^k}{p_1(1-p_2)}\\
        &=[1-(1-p_1)(1-p_2)](1-p_1)^{k-1}(1-p_2)^{k-1}
    \end{split}
\end{equation*}
\color{black}

\section*{Problem 3}
Player A and B are having a table tennis match; the first player to win 3 games wins the match. One of the players is better than the other; this better player wins each game with probability 0.7. Carl comes to watch the match. He does not know who is the better player so (based on Carl's information) A, B each initially have probability 0.5 to be the better player. Then Carl sees A win 2 of the first 3 games.
\subsection*{(a)}
What is now the probability (after the 3 games, based on Carl's information) that A is the better player? Simplify your answer to a single fraction or decimal.
\color{blue}
\\\\\textit{Solution.} Let $C=\{\text{A won 2 of the first 3 games}\}$, $A=\{\text{A is better}\}$, and $B=\{\text{B is better}\}$.
\begin{equation*}
    \begin{split}
        \prob(A\vert C) &= \prob(C\vert A)\frac{\prob(A)}{\prob(C)}\\
        &= {3 \choose 2} (0.7)^2(0.3) \frac{0.5}{\prob(C \cap A)+\prob(C\cap B)}\\
        &= {3 \choose 2} (0.7)^2(0.3) \frac{0.5}{{3 \choose 2} (0.7)^2(0.3)0.5+{3 \choose 2} (0.3)^2(0.7)0.5}\\
        &= \frac{7}{10}
    \end{split}
\end{equation*}
\color{black}
\subsection*{(b)}
What is now the probability (after 3 games, based on Carl's information) that A will go on to win the match? NOTE: Express your answer for (b) in terms of numbers; you do not need to simplify to a single number. Ananswer in a form like $\frac{5}{4}+7(2-\frac{9}{5})$ is OK.
\color{blue}
\\\\\textit{Solution. }Let $W_A=\prob(\text{A win a game}\vert C) = 0.7\cdot 0.7+0.3\cdot 0.3 = 0.58$, so $W_B=\prob(\text{B win a game}\vert C)=0.42$. So,
\begin{equation*}
    \begin{split}
        \prob(\text{A win the match}\vert C) &= W_A+W_BW_A\\
        &=0.58+0.42\cdot 0.58\\
        &= 0.8236
    \end{split}
\end{equation*}
\color{black}

\section*{Problem 4}
Suppose $X_n$ is binomial with parameters $(n,p)$ with $0\leq p\leq 1$, and $ X$ is Poisson($\lambda$).
\subsection*{(a)}
Find the moment generating function of $X_n$.
\color{blue}
\\\\\textit{Solution. }
\begin{equation*}
    \begin{split}
        \E(e^{X_nt}) &= \sum_{k=0}^n e^{tk}{n \choose k} p^k(1-p)^{n-k}\\
        &= \sum_{k=0}^n{n \choose k}p(pe^t)^k(1-p)^{n-k}\\
        &\stackrel{(*)}{=} (1-p+pe^t)^n
    \end{split}
\end{equation*}
$(*)$ Binomial formula.
\color{black}
\subsection*{(b)}
Suppose $n \rightarrow \infty$ and $p=p_n \rightarrow 0$ with $np \rightarrow \lambda \in (0,\infty)$. Show that $\prob(X_n=k) \rightarrow \prob(X=k) $ as $n\rightarrow \infty $, for all $k\geq 0$. HINT:$(1-\frac{c_n}{n})^n \rightarrow e^{-c} $ if $c_n \rightarrow c$.
\color{blue}
\begin{proof}
\begin{equation*}
    \begin{split}
        \lim_{n\rightarrow \infty}\prob(X_n = k)&=\lim_{n\rightarrow \infty}{n \choose k} p^k(1-p)^{n-k}\\
        &= \lim_{n\rightarrow \infty}\frac{1}{k!}\frac{n!}{(n-k)!}p^k(1-\frac{np}{n})^n(1-\frac{np}{n})^{-k}\\
        &= \frac{1}{k!}\lim_{n\rightarrow \infty}\frac{n-k+1}{n}\frac{n-k+2}{n}\cdots \frac{n-1}{n}\frac{n}{n}(np)^k(1-\frac{np}{n})^n(1- \frac{np}{n})^{-k}\\
        &= \frac{1}{k!}\cdot 1 \cdot 1 \cdots 1\cdot 1\cdot \lambda^k \cdot e^{-\lambda}\cdot 1\\
        &= e^{-\lambda}\frac{\lambda^k}{k!}
    \end{split}
\end{equation*}

\end{proof}
\color{black}
\subsection*{(c)}
For $n,p$ as in part(b), show that $\prob(X_n >k) \rightarrow \prob(X>k)$ as $n \rightarrow \infty$, for all $k\geq 0$.
\color{blue}
\begin{proof}
\begin{equation*}
    \begin{split}
        \lim_{n\rightarrow \infty}\prob(X_n>k) &= \lim_{n\rightarrow \infty}(1-\prob(X_n\leq k)\\
        &= 1-\lim_{n\rightarrow \infty}\sum_{x=0}^k\prob(X_n=x)\\
        &= 1-\sum_{x=0}^k\lim_{n\rightarrow \infty}\prob(X_n=x)\\
        &\stackrel{(**)}{=} 1-\sum_{x=0}^k\prob(X=x)\\
        &= \prob(X>k)
    \end{split}
\end{equation*}
$(**)$ Conclusion of (b).
\end{proof}
\end{document}
